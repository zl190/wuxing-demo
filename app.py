# -*- coding: utf-8 -*-
"""
Wuxing Demo - Five Elements Visualization
äº”è¡Œå¯è§†åŒ–ä¸è§£è¯»

Run: streamlit run app.py
"""

import streamlit as st
import numpy as np
import plotly.graph_objects as go
from datetime import datetime, date
from pathlib import Path
from openai import OpenAI

# ============ Constants ============
ELEMENTS = ['æœ¨ Wood', 'ç« Fire', 'åœŸ Earth', 'é‡‘ Metal', 'æ°´ Water']
ELEMENTS_SHORT = ['æœ¨', 'ç«', 'åœŸ', 'é‡‘', 'æ°´']
WOOD, FIRE, EARTH, METAL, WATER = range(5)

# Heavenly Stems (å¤©å¹²) -> Element mapping
STEMS = {
    'ç”²': WOOD, 'ä¹™': WOOD,
    'ä¸™': FIRE, 'ä¸': FIRE,
    'æˆŠ': EARTH, 'å·±': EARTH,
    'åºš': METAL, 'è¾›': METAL,
    'å£¬': WATER, 'ç™¸': WATER
}

# Earthly Branches (åœ°æ”¯) -> Element mapping (simplified, main element only)
BRANCHES = {
    'å­': WATER, 'ä¸‘': EARTH, 'å¯…': WOOD, 'å¯': WOOD,
    'è¾°': EARTH, 'å·³': FIRE, 'åˆ': FIRE, 'æœª': EARTH,
    'ç”³': METAL, 'é…‰': METAL, 'æˆŒ': EARTH, 'äº¥': WATER
}

STEM_LIST = ['ç”²', 'ä¹™', 'ä¸™', 'ä¸', 'æˆŠ', 'å·±', 'åºš', 'è¾›', 'å£¬', 'ç™¸']
BRANCH_LIST = ['å­', 'ä¸‘', 'å¯…', 'å¯', 'è¾°', 'å·³', 'åˆ', 'æœª', 'ç”³', 'é…‰', 'æˆŒ', 'äº¥']

# ============ BaZi Calculation (Simplified) ============
def get_stem_branch(year, month, day, hour):
    """
    Simplified BaZi calculation.
    Note: Real BaZi requires lunar calendar and solar terms. This is approximate.
    """
    # Year pillar (approximate)
    year_stem_idx = (year - 4) % 10
    year_branch_idx = (year - 4) % 12

    # Month pillar (very simplified)
    month_stem_idx = ((year - 4) % 5 * 2 + month) % 10
    month_branch_idx = (month + 1) % 12

    # Day pillar (simplified using a base date)
    base = datetime(1900, 1, 31)  # Known: ç”²å­æ—¥
    target = datetime(year, month, day)
    days_diff = (target - base).days
    day_stem_idx = days_diff % 10
    day_branch_idx = days_diff % 12

    # Hour pillar
    hour_branch_idx = ((hour + 1) // 2) % 12
    hour_stem_idx = (day_stem_idx % 5 * 2 + hour_branch_idx) % 10

    return [
        (STEM_LIST[year_stem_idx], BRANCH_LIST[year_branch_idx]),
        (STEM_LIST[month_stem_idx], BRANCH_LIST[month_branch_idx]),
        (STEM_LIST[day_stem_idx], BRANCH_LIST[day_branch_idx]),
        (STEM_LIST[hour_stem_idx], BRANCH_LIST[hour_branch_idx])
    ]

def bazi_to_matrix(pillars):
    """Convert BaZi pillars to 5x4 element distribution matrix"""
    X = np.zeros((5, 4))
    for col, (stem, branch) in enumerate(pillars):
        X[STEMS[stem], col] += 1
        X[BRANCHES[branch], col] += 1
    return X

# ============ LLM Narrative ============
def load_prompt_template():
    """Load prompt template from file"""
    prompt_file = Path(__file__).parent / "prompts" / "bazi_analyst.md"
    return prompt_file.read_text(encoding="utf-8")

def build_prompt(template, pillars, s, day_status):
    """Build the final prompt by replacing placeholders"""
    element_names = ['æœ¨', 'ç«', 'åœŸ', 'é‡‘', 'æ°´']
    dist_parts = [f"{element_names[i]}={s[i]:.1f}" for i in range(5)]

    return template.format(
        year_pillar=f"{pillars[0][0]}{pillars[0][1]}",
        month_pillar=f"{pillars[1][0]}{pillars[1][1]}",
        day_pillar=f"{pillars[2][0]}{pillars[2][1]}",
        hour_pillar=f"{pillars[3][0]}{pillars[3][1]}",
        elements_dist=', '.join(dist_parts),
        day_status=day_status
    )

def generate_llm_narrative(api_key, prompt, model="gpt-4o-mini"):
    """Generate narrative interpretation using LLM"""
    try:
        # Validate API key format
        api_key = api_key.strip()
        if not api_key.isascii():
            return "âŒ API Key æ ¼å¼é”™è¯¯ï¼šåŒ…å«é ASCII å­—ç¬¦ã€‚OpenAI key åº”è¯¥æ˜¯ sk-... æ ¼å¼ï¼Œåªå«è‹±æ–‡å­—æ¯å’Œæ•°å­—ã€‚"
        if not api_key.startswith("sk-"):
            return "âŒ API Key æ ¼å¼é”™è¯¯ï¼šåº”è¯¥ä»¥ sk- å¼€å¤´ã€‚"

        client = OpenAI(api_key=api_key)

        # o-series and gpt-5 models use max_completion_tokens, no temperature
        if model.startswith("o") or model.startswith("gpt-5"):
            response = client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": prompt}],
                max_completion_tokens=4000
            )
        else:
            response = client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=2000,
                temperature=0.7
            )
        return response.choices[0].message.content
    except Exception as e:
        import traceback
        return f"LLM è°ƒç”¨å¤±è´¥: {str(e)}\n\nè¯¦ç»†ä¿¡æ¯:\n{traceback.format_exc()}"

# ============ Visualization ============
def plot_radar(s, title="äº”è¡Œåˆ†å¸ƒ"):
    """Radar chart for element distribution"""
    fig = go.Figure()
    fig.add_trace(go.Scatterpolar(
        r=list(s) + [s[0]],
        theta=ELEMENTS + [ELEMENTS[0]],
        fill='toself',
        name='äº”è¡Œå¼ºåº¦'
    ))
    fig.update_layout(
        polar=dict(radialaxis=dict(visible=True, range=[0, max(s)*1.2+1])),
        showlegend=False,
        title=title,
        height=350
    )
    return fig

def plot_graph():
    """Plot the Wuxing graph structure"""
    # Pentagon coordinates
    angles = [np.pi/2 - 2*np.pi*i/5 for i in range(5)]
    x = [np.cos(a) for a in angles]
    y = [np.sin(a) for a in angles]

    fig = go.Figure()

    # Generating edges (adjacent, green)
    for i in range(5):
        j = (i + 1) % 5
        fig.add_trace(go.Scatter(
            x=[x[i], x[j]], y=[y[i], y[j]],
            mode='lines',
            line=dict(color='green', width=2),
            showlegend=False,
            hoverinfo='skip'
        ))

    # Controlling edges (skip one, red, dashed)
    for i in range(5):
        j = (i + 2) % 5
        fig.add_trace(go.Scatter(
            x=[x[i], x[j]], y=[y[i], y[j]],
            mode='lines',
            line=dict(color='red', width=1, dash='dash'),
            showlegend=False,
            hoverinfo='skip'
        ))

    # Nodes
    fig.add_trace(go.Scatter(
        x=x, y=y,
        mode='markers+text',
        marker=dict(size=40, color=['green', 'red', 'brown', 'gold', 'blue']),
        text=ELEMENTS_SHORT,
        textposition='middle center',
        textfont=dict(size=16, color='white'),
        hovertext=ELEMENTS,
        hoverinfo='text'
    ))

    fig.update_layout(
        showlegend=False,
        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False, scaleanchor='x'),
        height=300,
        margin=dict(l=20, r=20, t=30, b=20),
        title="äº”è¡Œå…³ç³»å›¾ (ç»¿=ç›¸ç”Ÿ, çº¢=ç›¸å…‹)"
    )
    return fig

# ============ Streamlit App ============
st.set_page_config(page_title="è®¡ç®—äººæ–‡", layout="wide")

st.title("è®¡ç®—äººæ–‡")
st.markdown("### äº”è¡Œ")
st.caption("è¾“å…¥ç”Ÿè¾°ï¼Œçœ‹äº”è¡Œåˆ†å¸ƒï¼Œç”Ÿæˆ AI è§£è¯»")

# Sidebar: Input
st.sidebar.header("ğŸ“… è¾“å…¥")

input_mode = st.sidebar.radio("è¾“å…¥æ–¹å¼", ["ç”Ÿæ—¥æ¨ç®—(ç®€åŒ–)", "æ‰‹åŠ¨å…«å­—"])

if input_mode == "ç”Ÿæ—¥æ¨ç®—(ç®€åŒ–)":
    birth_date = st.sidebar.date_input("å‡ºç”Ÿæ—¥æœŸ", date(1990, 1, 1))
    birth_hour = st.sidebar.slider("å‡ºç”Ÿæ—¶è¾° (0-23)", 0, 23, 12)
    pillars = get_stem_branch(birth_date.year, birth_date.month, birth_date.day, birth_hour)
else:
    st.sidebar.caption("é€‰æ‹©å››æŸ±å¤©å¹²åœ°æ”¯")
    col1, col2 = st.sidebar.columns(2)
    with col1:
        y_stem = st.selectbox("å¹´å¹²", STEM_LIST, index=8)
        m_stem = st.selectbox("æœˆå¹²", STEM_LIST, index=8)
        d_stem = st.selectbox("æ—¥å¹²", STEM_LIST, index=4)
        h_stem = st.selectbox("æ—¶å¹²", STEM_LIST, index=9)
    with col2:
        y_branch = st.selectbox("å¹´æ”¯", BRANCH_LIST, index=9)
        m_branch = st.selectbox("æœˆæ”¯", BRANCH_LIST, index=0)
        d_branch = st.selectbox("æ—¥æ”¯", BRANCH_LIST, index=2)
        h_branch = st.selectbox("æ—¶æ”¯", BRANCH_LIST, index=11)
    pillars = [(y_stem, y_branch), (m_stem, m_branch), (d_stem, d_branch), (h_stem, h_branch)]

# Display pillars
pillar_names = ['å¹´æŸ±', 'æœˆæŸ±', 'æ—¥æŸ±', 'æ—¶æŸ±']
st.sidebar.markdown("---")
st.sidebar.markdown("**å››æŸ±:**")
for name, (stem, branch) in zip(pillar_names, pillars):
    st.sidebar.markdown(f"- {name}: {stem}{branch}")

# Sidebar: LLM Settings
st.sidebar.header("ğŸ¤– AI è§£è¯» (å¯é€‰)")
with st.sidebar.expander("ğŸ” ä½¿ç”¨ OpenAI API"):
    st.caption("""
    **å®‰å…¨æç¤º**ï¼š
    - å»ºè®®ä½¿ç”¨ä¸“ç”¨ keyï¼ˆéä¸» keyï¼‰
    - è®¾ç½® spending limit
    - ç”¨å®Œåå» OpenAI åå° regenerate
    """)
    openai_api_key = st.text_input("API Key", type="password")
    use_llm = st.checkbox("å¯ç”¨ AI è§£è¯»", value=bool(openai_api_key), disabled=not openai_api_key)

# Calculate
w = np.array([1.0, 2.0, 1.0, 1.0])  # Default weights: emphasize month
X = bazi_to_matrix(pillars)
s = X @ w

# Day master element
day_stem = pillars[2][0]
day_element = STEMS[day_stem]
day_element_name = ELEMENTS[day_element]

# Main content
col1, col2 = st.columns([1, 1])

with col1:
    st.subheader("äº”è¡Œé›·è¾¾å›¾")
    st.plotly_chart(plot_radar(s), use_container_width=True)

with col2:
    st.subheader("äº”è¡Œå…³ç³»å›¾")
    st.plotly_chart(plot_graph(), use_container_width=True)

# Narrative explanation
st.subheader("ğŸ“– è§£è¯»")

sorted_elements = sorted(enumerate(s), key=lambda x: -x[1])
strongest_idx = sorted_elements[0][0]
weakest_idx = sorted_elements[-1][0]
strongest = ELEMENTS_SHORT[strongest_idx]
weakest = ELEMENTS_SHORT[weakest_idx]
day_el = ELEMENTS_SHORT[day_element]

avg_strength = np.mean(s)
day_strength = s[day_element]

# Determine day master status
if day_strength < avg_strength * 0.7:
    day_status = "åå¼±"
elif day_strength > avg_strength * 1.5:
    day_status = "åæ—º"
else:
    day_status = "ä¸­å’Œ"

st.markdown(f"""
**æ—¥ä¸»**: {day_stem} ({day_element_name}) â€” **{day_status}**

äº”è¡Œåˆ†å¸ƒ: **{strongest}** æœ€æ—º ({sorted_elements[0][1]:.1f})ï¼Œ**{weakest}** æœ€å¼± ({sorted_elements[-1][1]:.1f})

æ—¥ä¸» **{day_el}** å¼ºåº¦ {day_strength:.1f}ï¼Œå¹³å‡ {avg_strength:.1f}
""")

# Smart suggestions based on balance theory
gen_source = (day_element - 1) % 5  # element that generates day master
gen_target = (day_element + 1) % 5  # element that day master generates (drains)
ctl_source = (day_element + 2) % 5  # element that controls day master

gen_source_name = ELEMENTS_SHORT[gen_source]
gen_target_name = ELEMENTS_SHORT[gen_target]
ctl_source_name = ELEMENTS_SHORT[ctl_source]

st.markdown("---")
st.markdown("**è°ƒèŠ‚å»ºè®®ï¼š**")

if day_status == "åå¼±":
    st.markdown(f"""
    æ—¥ä¸» {day_el} åå¼±ï¼Œå¯è€ƒè™‘ï¼š
    - ğŸ”¥ **å¢åŠ  {gen_source_name}**ï¼ˆ{gen_source_name} ç”Ÿ {day_el}ï¼Œå¢å¼ºæ—¥ä¸»ï¼‰
    - ğŸ›¡ï¸ **å‡å°‘ {ctl_source_name}**ï¼ˆ{ctl_source_name} å…‹ {day_el}ï¼Œå‰Šå¼±æ—¥ä¸»ï¼‰
    """)
elif day_status == "åæ—º":
    st.markdown(f"""
    æ—¥ä¸» {day_el} åæ—ºï¼Œå¯è€ƒè™‘ï¼š
    - ğŸ’§ **å¢åŠ  {gen_target_name}**ï¼ˆ{day_el} ç”Ÿ {gen_target_name}ï¼Œæ³„æ—¥ä¸»ä¹‹æ°”ï¼‰
    - âš”ï¸ **å¢åŠ  {ctl_source_name}**ï¼ˆ{ctl_source_name} å…‹ {day_el}ï¼ŒæŠ‘åˆ¶æ—¥ä¸»ï¼‰
    """)
else:
    st.markdown(f"""
    æ—¥ä¸» {day_el} ä¸­å’Œï¼Œæ•´ä½“è¾ƒå¹³è¡¡ã€‚å¯æ ¹æ®å…·ä½“éœ€æ±‚å¾®è°ƒã€‚
    """)

# LLM-powered narrative (if enabled)
if use_llm and openai_api_key:
    st.markdown("---")
    st.markdown("### ğŸ¤– AI æ·±åº¦è§£è¯»")

    # Model selector and generate button in same row
    col_model, col_btn = st.columns([2, 1])
    with col_model:
        llm_model = st.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            ["gpt-5.2", "gpt-4.1", "gpt-4.1-mini", "gpt-4o", "gpt-4o-mini", "o3-mini", "o1"],
            index=0,
            help="gpt-5.2: æœ€æ–°æ——èˆ° | gpt-4.1: æœ€å¼ºéæ¨ç† | o3-mini: å¿«é€Ÿæ¨ç†",
            key="model_selector"
        )
    with col_btn:
        st.markdown("<br>", unsafe_allow_html=True)  # align with selectbox
        generate_btn = st.button("ğŸš€ ç”Ÿæˆè§£è¯»", key="llm_btn", use_container_width=True)

    if generate_btn:
        # Load prompt from file and build final prompt
        prompt_template = load_prompt_template()
        final_prompt = build_prompt(prompt_template, pillars, s, day_status)
        with st.spinner(f"æ­£åœ¨ç”¨ {llm_model} åˆ†æ..."):
            llm_narrative = generate_llm_narrative(
                openai_api_key, final_prompt, model=llm_model
            )
            st.markdown(llm_narrative)

# Footer
st.markdown("---")
st.caption("[ğŸ“ è®¡ç®—äººæ–‡ç‰ˆ](/DS) Â· [ğŸ§  åŸç†](https://zl190.github.io/blog/zh/wuxing-gnn) Â· ç”¨ç°ä»£æ¡†æ¶è§£æ„ä¼ ç»Ÿç³»ç»Ÿ")
